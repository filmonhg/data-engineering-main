[2023-11-05T16:31:36.575+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_People_Places.load_people manual__2023-11-05T16:31:25.456313+00:00 [queued]>
[2023-11-05T16:31:36.589+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_People_Places.load_people manual__2023-11-05T16:31:25.456313+00:00 [queued]>
[2023-11-05T16:31:36.590+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-11-05T16:31:36.592+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-11-05T16:31:36.593+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-11-05T16:31:36.615+0000] {taskinstance.py:1309} INFO - Executing <Task(DockerOperator): load_people> on 2023-11-05 16:31:25.456313+00:00
[2023-11-05T16:31:36.620+0000] {standard_task_runner.py:55} INFO - Started process 1340 to run task
[2023-11-05T16:31:36.624+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'ETL_People_Places', 'load_people', 'manual__2023-11-05T16:31:25.456313+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ETL_people_places_dag.py', '--cfg-path', '/tmp/tmpdvxllo9f']
[2023-11-05T16:31:36.628+0000] {standard_task_runner.py:83} INFO - Job 34: Subtask load_people
[2023-11-05T16:31:36.714+0000] {task_command.py:389} INFO - Running <TaskInstance: ETL_People_Places.load_people manual__2023-11-05T16:31:25.456313+00:00 [running]> on host 526ca62ab683
[2023-11-05T16:31:36.817+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=***@example.com
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=ETL_People_Places
AIRFLOW_CTX_TASK_ID=load_people
AIRFLOW_CTX_EXECUTION_DATE=2023-11-05T16:31:25.456313+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-11-05T16:31:25.456313+00:00
[2023-11-05T16:31:36.855+0000] {docker.py:306} INFO - Starting docker container from image load_people:latest
[2023-11-05T16:31:37.260+0000] {docker.py:373} INFO - Traceback (most recent call last):
  File "//main.py", line 22, in <module>
    with open('data/places.csv', 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'data/places.csv'
[2023-11-05T16:31:37.431+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 448, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 323, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 382, in _run_image_with_mounts
    raise AirflowException(f"Docker container failed: {repr(result)} lines {joined_log_lines}")
airflow.exceptions.AirflowException: Docker container failed: {'StatusCode': 1} lines Traceback (most recent call last):
  File "//main.py", line 22, in <module>
    with open('data/places.csv', 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'data/places.csv'
[2023-11-05T16:31:37.437+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=ETL_People_Places, task_id=load_people, execution_date=20231105T163125, start_date=20231105T163136, end_date=20231105T163137
[2023-11-05T16:31:37.455+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 34 for task load_people (Docker container failed: {'StatusCode': 1} lines Traceback (most recent call last):
  File "//main.py", line 22, in <module>
    with open('data/places.csv', 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'data/places.csv'; 1340)
[2023-11-05T16:31:37.487+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-11-05T16:31:37.539+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
